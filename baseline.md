# BASELINE
Построенно несколько линейных моделей машинного обучения для предсказания темы вопроса по его текстовому описанию и нескольким другим признакам, а именно:
* page - номер страницы на которой расположен вопрос в экзамене
* score
* year
* qst_len - длина предобработанного вопроса (под предобработкой понимается лемматизация, токенизация, удаление стоп-слов)

Для векторизации вопросов во всех моделях использовался метод TF-IDF для столбца `qst_processed` - лемматизированных, токенизированных вопросов с удаленными стоп-словами.

Все эксперименты находятся в файле `ml_model.ipynb`.

## Описание моделей
##### Note: во всех моделях (кроме случайного предсказания и предсказания по n-грамме) параметры подбирались с помощью GridSearchCV

1) Логистическая регрессия:
Подобранные параметры: LogisticRegression(C=103, max_iter=10000, multi_class='ovr')
    * f1-score macro на тестовой: 0.64
    * f1-score weighted на тестовой: 0.73
    * Roc-Auc на тестовой: 0.943

2) N-Grams + Naive bayes 
Подобранные параметры: MultinomialNB(alpha=1e-10)
    * f1-score macro на тестовой: 0.46
    * f1-score weighted на тестовой: 0.56
    * Roc-Auc на тестовой: 0.909

3) Линейный SVM
Подобранные параметры: LinearSVC(C=1e-05)
    * f1-score macro на тестовой: 0.10
    * f1-score weighted на тестовой: 0.20 
    * Roc-Auc на тестовой: 0.622

4) Случайное предсказание класса:
    * f1-score macro на тестовой: 0.12
    * f1-score weighted на тестовой: 0.18 
    * Roc-Auc на тестовой: 0.383

5) Предсказание класса по наиболее частой n-грамме
 
 #### Описание метода: на трейн-выборке получаем из вопросов все n-gramm'ы (n=1, 2, 3)
 Для каждой n-gramm'ы находится класс, в котором она чаще всего встречается на train-выборке
 При получении на вход нового вопроса, модель находит самую часто-встречающуюся на трейн-выборке n-gramm'у  из n-gramm в вопросе и по ней предсказывает класс.

* f1-score macro на тестовой: 0.18
* f1-score weighted на тестовой: 0.28 


По полученым метрикам можно сделать вывод, что лучше всего тему вопроса предсказывает `Логистическая регрессия`.
Пайплайн обучения Логистической регрессии лежит в `pipeline.ipynb`



